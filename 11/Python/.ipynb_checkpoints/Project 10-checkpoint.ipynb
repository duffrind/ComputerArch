{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling Jack\n",
    "\n",
    "Last week, we wrote some interesting programs in the Jack programming language. We saw that Jack was a high level language, with syntax similar to Java. This week we'll begin the process of writing a program that can translate Jack code into VM Language code. The resulting _compiler_ will be the last link in a tool chain that allows us to convert complex thoughts into code that can execute on a computer. \n",
    "\n",
    "Like the virtual machine translator we wrote in weeks 7 and 8, the compiler will be split into two projects. This week will be devoted only to writing the tokenizer and parser modules of our compiler, while week 11 will focus on generating code using the parser we'll write this week. \n",
    "\n",
    "## Parsing and Tokenizing\n",
    "\n",
    "Recall that _parsing_ is the act of extracting meaning from a statement or program. For example, when you read this sentence, your brain is parsing the individual words by assigning meaning to them, and then to the larger units like phrases or sentences.\n",
    "\n",
    "Besides parsing a sentence, our brains are also engaged in a process called _tokenization_. Tokenization is the process of splitting input into tokens that will have some meaning. When we write, we usually use spaces to signal the boundraries of individual tokens. When we speak, we pause between words to indicate the boundaries. In some contexts it can be more difficult to find the tokens. For example, in German, large compound words are permitted, like \"Siebentausendzweihundertvierundfünfzig\". Careful reading reveals that this reduces to \"Sieben tausend zwei hundert vier und fünfzig\", which translates to \"Seven thousand, two hundred, four and fifty\".\n",
    "\n",
    "In Jack there are only 5 types of tokens: Keywords, symbols, identifiers, integers, and strings.\n",
    "\n",
    "- Keywords: any of the reserved words in the Jack language. These words have special meanings. Examples: class, int, do, static\n",
    "- Symbols: These are special characters that indicate some operation or scope. Examples: {, +, =\n",
    "- Identifiers: These are the names of variables, classes, functions or methods. They can be any sequence of letters, numbers, and '\\_', as long as the sequence does not begin with a number. Examples: Square, foo, bar\n",
    "- Integers: Any sequence of only digits. Examples: 123\n",
    "- Strings: Any sequence of charactors that starts with \" and ends with \", all appearing on the same line. Examples: \"dog\", \"cat\", \"Square\", \"5\"\n",
    "\n",
    "\n",
    "Notice: \n",
    "- Tokens might have spaces or newlines in between them.\n",
    "- Any token that starts with a double quote (\") is a String.\n",
    "- Any token that starts with a number is an Integer.\n",
    "- Any token that starts with neither a number, a letter or a double quote is a Symbol.\n",
    "- Any token that isn't a String, an Integer, or a Symbol must be a keyword or an identifier. We can check it against a list of keywords to figure out which it is.\n",
    "\n",
    "Unlike in past weeks, the IO module for project 10 does not read an entire line at once. Rather, two useful functions are provided:\n",
    "\n",
    "- IO.peek() returns the next charactor in the input, but this charactor remains at the front of the input, and is not read.\n",
    "- IO.consume() returns nothing, but consumes (reads) one charactor from the input.\n",
    "\n",
    "Here's an example:\n",
    "\n",
    "```python\n",
    "  #Suppose that the user has entered \"alligator\".\n",
    "  \n",
    "  IO.peek() #returns \"a\"\n",
    "  IO.peek() #still returns \"a\"\n",
    "  \n",
    "  IO.consume() #returns nothing, consumes the 'a'\n",
    "  \n",
    "  IO.peek() #returns \"l\"\n",
    "  IO.peek() #still returns \"l\"\n",
    "  \n",
    "  IO.consume() # returns nothing, consumes the 'l'\n",
    "  IO.consume() # returns nothing, consumes the other 'l'\n",
    "  IO.consume() # returns nothing, consumes the 'i'.\n",
    "  \n",
    "  IO.peek() #returns \"g\"\n",
    "  IO.peek() #still returns \"g\"\n",
    "```\n",
    "\n",
    "Apart from this, it will be useful to remember the following bits of Python syntax:\n",
    "\n",
    "- You can add to a string s by writing, e.g. ```s=s+\"abc\"```. \n",
    "- A while loop behaves much like a loop from Hack assembly. The commands in the body of the loop are repeated until the condition at the top of the loop is false.\n",
    "- You can check whether or not something is in a list by using the 'in' operator. For example:\n",
    "  ```python\n",
    "     \"alligator\" in [\"dog\", \"cat\", \"mouse\"] #False\n",
    "     \"dog\" in [\"dog\", \"cat\", \"mouse\"] #True```\n",
    "     \n",
    "- If you have a string s, then s.isdigit() is true only if s contains nothing but numbers.\n",
    "- If you have a string s, then s.isspace() is true only if s contains nothing but whitespace.\n",
    "- If you have a string s, then s.isalpha() is true only if s contains nothing but letters.\n",
    "- If you have a string s, then s.isalnum() is true only if s contains nothing but letters _or_ numbers.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Tokenizer Module\n",
    "import Project10IO as IO\n",
    "\n",
    "\n",
    "#Like the parser modules from earlier Projects, the Tokenizer\n",
    "# will advance one token at a time, and populate these global\n",
    "# variables.\n",
    "nextType=\"\"\n",
    "nextInt=\"\"\n",
    "nextString=\"\"\n",
    "nextSymbol=\"\"\n",
    "nextKW=\"\"\n",
    "nextID=\"\"\n",
    "\n",
    "#A function to check whether there are more tokens.\n",
    "def hasMoreTokens():\n",
    "    global line\n",
    "    if line == \"EOF\":\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#Consumes characters until \n",
    "# the next character in the stream is c.\n",
    "#Returns a string containing all the characters\n",
    "# that were consumed.\n",
    "def eatUntil(c):\n",
    "    s = \"\"\n",
    "    while IO.peek() != c:\n",
    "        s = s+IO.peek()\n",
    "        IO.consume()\n",
    "    return s\n",
    "\n",
    "#This function should be called when\n",
    "# the next token is a string. It consumes\n",
    "# everything between the next two quotation marks, including the quotes.\n",
    "# After the function is called, nextType should be STRING_CONST\n",
    "# and nextSTring should be whatever was between the quotes.\n",
    "def consumeString():\n",
    "    global nextType, nextString\n",
    "    s = \"\"\n",
    "    IO.consume() #eat the first quote.\n",
    "    while IO.peek() != '\"':\n",
    "        s = s+IO.peek()\n",
    "        IO.consume()\n",
    "    IO.consume() #eat the trailing quote.\n",
    "    nextType = \"STRING_CONST\"\n",
    "    nextString = s\n",
    "    \n",
    "#This function should be called when\n",
    "# the next token is a integer. It consumes\n",
    "# everything up to, but not including, the next non-numeric character.\n",
    "# After the function is called, nextType should be INT_CONST\n",
    "# and nextInt should be all the numbers that were consumed.  \n",
    "def consumeInt():\n",
    "    global nextType, nextInt\n",
    "    s = \"\"\n",
    "    while IO.peek().isdigit():\n",
    "        s = s + IO.peek()\n",
    "        IO.consume()\n",
    "    nextType = \"INT_CONST\"\n",
    "    nextInt = int(s)\n",
    "\n",
    "#This function peeks at the next character to check whether the \n",
    "# next token is a Symbol. A symbol is any character that isn't \n",
    "# a number, letter, or underscore. The function returns True\n",
    "# if the next token is a symbol, and False otherwise.\n",
    "def isSymbol():\n",
    "    s = IO.peek()\n",
    "    if not IO.peek().isalnum() and s != \"_\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "#This function should be called when\n",
    "# the next token is a symbol. It consumes only the next character.\n",
    "# After the function is called, nextType should be SYMBOL\n",
    "# and nextSymbol should be the consumed character.\n",
    "def consumeSymbol():\n",
    "    global nextSymbol, nextType\n",
    "    nextType = \"SYMBOL\"\n",
    "    nextSymbol = IO.peek()\n",
    "    IO.consume()\n",
    "\n",
    "#This function should be called when\n",
    "# the next token is either a Keyword or an Identifier. It consumes \n",
    "# everything up to the next character that is not a letter, number or _.\n",
    "# After the function is called, if the consumed characters form a keyword,\n",
    "# nextType should be KEYWORD, and nextKW should be equal to the consumed \n",
    "# string. Otherwise, nextType should be IDENTIFIER, and nextID should be \n",
    "# equal to the consumed string.\n",
    "def consumeKWorID():\n",
    "    global nextID, nextType, nextKW\n",
    "    s = \"\"\n",
    "    while IO.peek().isalpha() or IO.peek().isdigit() or IO.peek() == \"_\":\n",
    "        s = s + IO.peek()\n",
    "        IO.consume()\n",
    "\n",
    "    KWlist = ['class', 'constructor', 'function', 'method', 'field', \n",
    "              'static', 'var', 'int', 'char', 'boolean', 'void',\n",
    "              'true', 'false', 'null', 'this', 'let', 'do', 'if', \n",
    "              'else', 'while', 'return']      \n",
    "    if s in KWlist:\n",
    "        nextKW = s\n",
    "        nextType = \"KEYWORD\"\n",
    "    else:\n",
    "        nextID = s\n",
    "        nextType = \"IDENTIFIER\"\n",
    "    \n",
    "\n",
    "#When this function is called any whitespace before the next token is consumed,\n",
    "#and then the next token is consumed, and the global variables are populated \n",
    "# accordingly.\n",
    "def advance():    \n",
    "    #Eat any leading whitespace or comments\n",
    "    IO.eatUntilNextToken()\n",
    "    \n",
    "    #Use the first charactor to decide what to consume next.\n",
    "    firstChar = IO.peek()    \n",
    "    if firstChar == '\"':\n",
    "        consumeString()\n",
    "    elif firstChar.isdigit():\n",
    "        consumeInt()\n",
    "    elif isSymbol():\n",
    "        consumeSymbol()\n",
    "    else:\n",
    "        consumeKWorID()\n",
    "\n",
    "#The remaining functions simply provide a way to access\n",
    "# the populated global variables, and print error messages\n",
    "# if they are accessed improperly.\n",
    "def tokenType():\n",
    "    global nextType\n",
    "    return nextType\n",
    "    \n",
    "def keyword():\n",
    "    global nextType, nextKW\n",
    "    if nextType == \"KEYWORD\":\n",
    "        return nextKW\n",
    "    else:\n",
    "        raise(\"Value error! Called keyWord() on line: \" +IO.currentLine())\n",
    "\n",
    "def symbol():\n",
    "    global nextSymbol, nextType\n",
    "    if nextType == \"SYMBOL\":\n",
    "        return nextSymbol\n",
    "    else:\n",
    "        raise(\"Value error! Called symbol() on line: \" +IO.currentLine())\n",
    "\n",
    "\n",
    "def identifier():\n",
    "    global nextID, nextType\n",
    "    if nextType == \"IDENTIFIER\":\n",
    "        return nextID\n",
    "    else:\n",
    "        raise(\"Value error! Called identifier() on line: \" +IO.currentLine())\n",
    "\n",
    "\n",
    "def intVal():\n",
    "    global nextInt, nextType\n",
    "    if nextType == \"INT_CONST\":\n",
    "        return str(nextInt)\n",
    "    else:\n",
    "        raise(\"Value error! Called intVal() on line: \" +IO.currentLine())\n",
    "\n",
    "\n",
    "def stringVal():\n",
    "    global nextString, nextType\n",
    "    if nextType == \"STRING_CONST\":\n",
    "        return nextString\n",
    "    else:\n",
    "        raise(\"Value error! Called stringVal() on line: \" +IO.currentLine())\n",
    "\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Utilities Module\n",
    "#This module contains a number of functions that will\n",
    "# be exceedingly useful when we write the Parser.\n",
    "#These functions do not need to be modified, and only the top four will \n",
    "# be directly used in the next section. Make sure you understand what \n",
    "# the top four do though, and how to use them.\n",
    "\n",
    "#verifyToken accepts two arguments, ttype and token.\n",
    "# If the next token is of type ttype, and has exactly \n",
    "# the same value as the token argument, then the token is\n",
    "# consumed, and printed using the printTerminal command.\n",
    "# Otherwise, the program halts by calling compileError.\n",
    "# The type is not case sensitive. \n",
    "# Example: verifyToken(\"SYMBOL\", \";\")\n",
    "# Example: verifyToken(\"keyword\", \"while\")\n",
    "def verifyToken(ttype, token=\"\", peek=False):\n",
    "    result = \"\"\n",
    "    if tokenType() != ttype.upper() or (getNextToken() != token and token != \"\"):\n",
    "        if not peek:\n",
    "            compileError(ttype,token)\n",
    "        return False\n",
    "    else:\n",
    "        if not peek:\n",
    "            printTerminal(ttype.lower(), getNextToken())\n",
    "            advance()\n",
    "        return True\n",
    "\n",
    "#peekToken returns true if the next token matches the \n",
    "# type and value of the passed arguments. The token type\n",
    "# is not case sensitive.\n",
    "# Example: if peekToken(\"symbol\", \";\"):\n",
    "#              //do something if the next token is ';'.\n",
    "#          else\n",
    "#              //do something if the next token is not ';'.\n",
    "def peekToken(ttype, tvalue):\n",
    "    return verifyToken(ttype, tvalue, peek=True)\n",
    "    \n",
    "#Like verifyToken, but tokenList should be a list of possible\n",
    "# token values, and the program will halt with an error if \n",
    "# the next token is _none_ of the listed values.\n",
    "# Example: verifyTokenList(\"keyword\", [\"let\", \"do\", \"if\", \"while\", \"return\"])\n",
    "def verifyTokenList(ttype, tokenList, peek=False):\n",
    "    for t in tokenList:\n",
    "        if peekToken(ttype, t):\n",
    "            if not peek:\n",
    "                printTerminal(ttype.lower(), getNextToken())\n",
    "                advance()\n",
    "            return True\n",
    "    if not peek:\n",
    "        compileError(ttype, tokenList)\n",
    "    return False\n",
    "\n",
    "#List peekToken, but returns true if _any_ of the values in\n",
    "# tvalueList match the next token, and the next token is of the\n",
    "# listed type.\n",
    "def peekTokenList(ttype, tvalueList):\n",
    "    return verifyTokenList(ttype, tvalueList, peek=True)\n",
    "\n",
    "\n",
    "#Returns the next token, whatever it is.\n",
    "def getNextToken():\n",
    "    if tokenType() == \"STRING_CONST\":\n",
    "        return stringVal()\n",
    "    if tokenType() == \"INT_CONST\":\n",
    "         return intVal()\n",
    "    if tokenType() == \"IDENTIFIER\":\n",
    "        return identifier()\n",
    "    if tokenType() == \"SYMBOL\":\n",
    "        return symbol()    \n",
    "    if tokenType() == \"KEYWORD\":\n",
    "        return keyword()\n",
    "    return \"ERROR!!!\"\n",
    "\n",
    "#Halts the program and prints an error message.\n",
    "def compileError( ttype, token):\n",
    "    s = \"Compilation error. Expected token \\\"\" + token + \"\\\" of type \\\"\" + ttype + \"\\\"\\n\"\n",
    "    s = s + \"Found token type \\\"\"+tokenType() + \"\\\" with value \\\"\"\n",
    "    s = s + getNextToken() + \"\\\"\"\n",
    "    raise ValueError(s)   \n",
    "\n",
    "#Prints a terminal value in the correct format\n",
    "# <type> value </type>\n",
    "def printTerminal(ttype, token):\n",
    "    if token == \"<\":\n",
    "        token = \"&lt;\"\n",
    "    if token == \">\":\n",
    "        token = \"&gt;\"\n",
    "    if token == \"&\":\n",
    "        token = \"&amp;\"\n",
    "    if ttype == \"string_const\":\n",
    "        ttype = \"stringConstant\"\n",
    "    if ttype == \"int_const\":\n",
    "        ttype = \"integerConstant\"\n",
    "    print(\"<\"+ttype+\"> \"+token+\" </\"+ttype+\">\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing the Parser Module\n",
    "\n",
    "Now that we've finished the tokenizer, it's time to write the Parser. This week, our parser will output its code as XML (eXtensible Markup Language; the X makes it cooler...). XML is a widely used format for data that's passed around the internet, or between different programs. \n",
    "\n",
    "Next week, we'll modify the parser module to instead output VM code, completing the compiler.\n",
    "\n",
    "\n",
    "XML code consists of pairs of nested tags surrounding data. For example:\n",
    "\n",
    "<class>\n",
    "  <keyword>\n",
    "    class\n",
    "  </keyword>\n",
    "  <identifier>\n",
    "    myclass\n",
    "  </identifier>\n",
    "</class>\n",
    "\n",
    "represents the start of a Jack class called myclass. The tags tell us how to understand each part of the data. For instance, the data \"class\" is a keyword (since it's inside the <keyword> tags) that is part of the declaration of a class (since it's inside the <class> tags). Similarily, myclass is an identifier that's part of this class.\n",
    "\n",
    "In the parser module, we'll implement the grammar found in table 10.5 of the textbook. If an input program is grammatically correct, our module will output the corresponding XML code. If the program is grammatically incorrect, our program will halt and produce a compilation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Program Structure Parsing Module\n",
    "#This Module contains the parsing functions for\n",
    "# the second box in Figure 10.5 of your textbook.\n",
    "# The third and fourth boxes are handelled in the Statement Parsing Module.\n",
    "\n",
    "#Each function should either consume a non-terminal of the \n",
    "# corresponding type, and write out the appropreate XML,\n",
    "# or should cause a compilerError to be produced, if the next\n",
    "# token is not of the right type.\n",
    "\n",
    "def CompileClass():\n",
    "    print(\"<class>\")\n",
    "    verifyToken(\"keyword\", \"class\")\n",
    "    verifyToken(\"identifier\",\"\")\n",
    "    verifyToken(\"symbol\", \"{\")\n",
    "\n",
    "    while peekTokenList(\"keyword\", [\"static\",\"field\"]):\n",
    "        CompileClassVarDec()\n",
    "    \n",
    "    while peekTokenList(\"keyword\", [\"constructor\", \"function\", \"method\"]):\n",
    "        CompileSubroutine()\n",
    "    \n",
    "    verifyToken(\"symbol\", \"}\")\n",
    "    print(\"</class>\")\n",
    "    \n",
    "def compileType():\n",
    "    if peekTokenList(\"keyword\", [\"int\", \"char\", \"boolean\"]):\n",
    "        verifyTokenList(\"keyword\", [\"int\", \"char\", \"boolean\"])\n",
    "    else:\n",
    "        verifyToken(\"identifier\", \"\")\n",
    "    \n",
    "def CompileClassVarDec():\n",
    "    print(\"<classVarDec>\")\n",
    "    verifyTokenList(\"keyword\", [\"static\",\"field\"])\n",
    "    \n",
    "    compileType()\n",
    "    verifyToken(\"identifier\", \"\")\n",
    "    while peekToken(\"symbol\", \",\"):\n",
    "        verifyToken(\"symbol\", \",\")\n",
    "        verifyToken(\"identifier\", \"\")\n",
    "        \n",
    "    verifyToken(\"symbol\", \";\")\n",
    "    print(\"</classVarDec>\")\n",
    "    \n",
    "def CompileSubroutine():\n",
    "    print(\"<subroutineDec>\")\n",
    "    verifyTokenList(\"keyword\", [\"constructor\",\"function\",\"method\"])\n",
    "    \n",
    "    if peekToken(\"keyword\", \"void\"):\n",
    "        verifyToken(\"keyword\", \"void\")\n",
    "    else:\n",
    "        verifyToken(\"identifier\",\"\")\n",
    "    \n",
    "    verifyToken(\"identifier\", \"\")\n",
    "    verifyToken(\"symbol\", \"(\")\n",
    "    compileParameterList()\n",
    "    verifyToken(\"symbol\", \")\")\n",
    "    compileSubroutineBody()\n",
    "    \n",
    "    print(\"</subroutineDec>\")\n",
    "\n",
    "def compileSubroutineBody():\n",
    "    print(\"<subroutineBody>\")\n",
    "    verifyToken(\"symbol\", \"{\")\n",
    "    while peekToken(\"keyword\", \"var\"):\n",
    "        compileVarDec()\n",
    "    compileStatements()    \n",
    "    verifyToken(\"symbol\",\"}\")\n",
    "    print(\"</subroutineBody>\")\n",
    "    \n",
    "def compileVarDec():\n",
    "    print(\"<varDec>\")\n",
    "    verifyToken(\"keyword\", \"var\")\n",
    "    compileType()\n",
    "    verifyToken(\"identifier\", \"\")\n",
    "    while peekToken(\"symbol\", \",\"):\n",
    "        verifyToken(\"symbol\", \",\")\n",
    "        verifyToken(\"identifier\",\"\")\n",
    "    verifyToken(\"symbol\", \";\")\n",
    "    print(\"</varDec>\")\n",
    "    \n",
    "def compileParameterList():\n",
    "    print(\"<parameterList>\")\n",
    "    if not peekToken(\"symbol\", \")\"):\n",
    "        compileType()\n",
    "        verifyToken(\"identifier\",\"\")\n",
    "        while peekToken(\"symbol\", \",\"):\n",
    "            verifyToken(\"symbol\", \",\")\n",
    "            compileType()\n",
    "            verifyToken(\"identifier\",\"\")\n",
    "        \n",
    "    print(\"</parameterList>\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#The Statement Parser Module is responsiable\n",
    "#for parsing Statements and Expressions, per\n",
    "# the last two boxes of Figure 10.5.\n",
    "\n",
    "#Each function should either consume a non-terminal of the \n",
    "# corresponding type, and write out the appropreate XML,\n",
    "# or should cause a compilerError to be produced, if the next\n",
    "# token is not of the right type.\n",
    "\n",
    "def compileStatements():\n",
    "    print(\"<statements>\")\n",
    "    while peekTokenList(\"keyword\", [\"if\", \"let\", \"while\", \"do\", \"return\"]):\n",
    "        if peekToken(\"keyword\", \"if\"):\n",
    "            compileIf()\n",
    "        elif peekToken(\"keyword\", \"let\"):\n",
    "            compileLet()\n",
    "        elif peekToken(\"keyword\", \"while\"):\n",
    "            compileWhile()\n",
    "        elif peekToken(\"keyword\", \"do\"):\n",
    "            compileDo()\n",
    "        elif peekToken(\"keyword\", \"return\"):\n",
    "            compileReturn()\n",
    "    print(\"</statements>\")\n",
    "    \n",
    "def compileDo():\n",
    "    print(\"<doStatement>\")\n",
    "    verifyToken(\"keyword\", \"do\")\n",
    "    verifyToken(\"identifier\", \"\")\n",
    "    if peekToken(\"symbol\", \".\"):\n",
    "        verifyToken(\"symbol\", \".\")\n",
    "        verifyToken(\"identifier\", \"\")\n",
    "    verifyToken(\"symbol\", \"(\")\n",
    "    CompileExpressionList()\n",
    "    verifyToken(\"symbol\", \")\")\n",
    "    \n",
    "    verifyToken(\"symbol\", ';')\n",
    "    print(\"</doStatement>\")\n",
    "    \n",
    "def compileLet():\n",
    "    print(\"<letStatement>\")\n",
    "    verifyToken(\"keyword\", \"let\")\n",
    "    verifyToken(\"identifier\",\"\")\n",
    "    \n",
    "    if peekToken(\"symbol\", \"[\"):\n",
    "        verifyToken(\"symbol\", \"[\")\n",
    "        CompileExpression()\n",
    "        verifyToken(\"symbol\", \"]\")\n",
    "    verifyToken(\"symbol\", \"=\")\n",
    "    CompileExpression()\n",
    "    verifyToken(\"symbol\", \";\")\n",
    "    print(\"</letStatement>\")\n",
    "    \n",
    "def compileWhile():\n",
    "    print(\"<whileStatement>\")\n",
    "    verifyToken(\"keyword\", \"while\")\n",
    "    verifyToken(\"symbol\", \"(\")\n",
    "    CompileExpression()\n",
    "    verifyToken(\"symbol\", \")\")\n",
    "    verifyToken(\"symbol\",\"{\")\n",
    "    compileStatements()\n",
    "    verifyToken(\"symbol\", \"}\")\n",
    "    print(\"</whileStatement>\")\n",
    "    \n",
    "def compileReturn():\n",
    "    print(\"<returnStatement>\")\n",
    "    verifyToken(\"keyword\", \"return\")\n",
    "    if not peekToken(\"symbol\", \";\"):\n",
    "        CompileExpression()\n",
    "    \n",
    "    verifyToken(\"symbol\", \";\")\n",
    "    print(\"</returnStatement>\")\n",
    "    \n",
    "def compileIf():\n",
    "    print(\"<ifStatement>\")\n",
    "    verifyToken(\"keyword\", \"if\")\n",
    "    verifyToken(\"symbol\", \"(\")\n",
    "    CompileExpression()\n",
    "    verifyToken(\"symbol\", \")\")\n",
    "    verifyToken(\"symbol\", \"{\")\n",
    "    compileStatements()\n",
    "    verifyToken(\"symbol\", \"}\")\n",
    "    \n",
    "    if peekToken(\"keyword\", \"else\"):\n",
    "        verifyToken(\"keyword\", \"else\")\n",
    "        verifyToken(\"symbol\", \"{\")\n",
    "        compileStatements()\n",
    "        verifyToken(\"symbol\", \"}\")\n",
    "    print(\"</ifStatement>\")\n",
    "    \n",
    "def CompileExpression():\n",
    "    print(\"<expression>\")\n",
    "    CompileTerm()\n",
    "    if peekTokenList(\"symbol\", [\"+\",\"-\",\"*\",\"/\",\"&\",\"|\",\"<\",\">\",\"=\"]):\n",
    "        verifyTokenList(\"symbol\", [\"+\",\"-\",\"*\",\"/\",\"&\",\"|\",\"<\",\">\",\"=\"])\n",
    "        CompileTerm()\n",
    "    print(\"</expression>\")\n",
    "    \n",
    "def CompileTerm():\n",
    "    print(\"<term>\")\n",
    "    if peekToken(\"int_const\", \"\"):\n",
    "        verifyToken(\"int_const\", \"\")\n",
    "    elif peekToken(\"string_const\", \"\"):\n",
    "        verifyToken(\"string_const\", \"\")\n",
    "    elif peekTokenList(\"keyword\", [\"true\", \"false\", \"null\", \"this\"]):\n",
    "        verifyTokenList(\"keyword\", [\"true\", \"false\", \"null\", \"this\"])\n",
    "    elif peekToken(\"identifier\", \"\"):\n",
    "        verifyToken(\"identifier\", \"\")\n",
    "        if peekToken(\"symbol\", \"[\"):\n",
    "            verifyToken(\"symbol\", \"[\")\n",
    "            CompileExpression()\n",
    "            verifyToken(\"symbol\", \"]\")\n",
    "        elif peekToken(\"symbol\", \"(\"):\n",
    "            verifyToken(\"symbol\", \"(\")\n",
    "            CompileExpressionList()\n",
    "            verifyToken(\"symbol\", \")\")\n",
    "        elif peekToken(\"symbol\", \".\"):\n",
    "            verifyToken(\"symbol\", \".\")\n",
    "            verifyToken(\"identifier\", \"\")\n",
    "            verifyToken(\"symbol\", \"(\")\n",
    "            CompileExpressionList()\n",
    "            verifyToken(\"symbol\", \")\")\n",
    "    elif peekToken(\"symbol\", \"(\"):\n",
    "            verifyToken(\"symbol\", \"(\")\n",
    "            CompileExpression()\n",
    "            verifyToken(\"symbol\", \")\")\n",
    "    else: \n",
    "        verifyTokenList(\"symbol\", [\"-\", \"~\"])\n",
    "        CompileTerm()\n",
    "    print(\"</term>\")\n",
    "    \n",
    "def CompileExpressionList():\n",
    "    print(\"<expressionList>\")\n",
    "    if not peekToken(\"symbol\", \")\"):\n",
    "        CompileExpression()\n",
    "        while peekToken(\"symbol\", \",\"):\n",
    "            verifyToken(\"symbol\", \",\")\n",
    "            CompileExpression()\n",
    "    print(\"</expressionList>\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing our Parser\n",
    "\n",
    "The short program in the cell below can be used to test the parser. It will cause the parser to process each of the provided test files.\n",
    "\n",
    "All the test files are grammatically correct, so if your program fails to parse them, you will need to figure out why.\n",
    "\n",
    "Once your program is able to parse all the test files, you need to make sure that its output is correct. Doing this will require the use of the TextComparer tool, distributed with the other course tools. This is a commandline tool, and its proper use will be demonstrated in the workshop.\n",
    "\n",
    "When the TextComparer tool confirms that your Parser has output the correct XML code for each file, your project is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def Compile(testname, filename):\n",
    "    IO.setFile(os.path.join('..',testname,filename+'.Jack'))\n",
    "    IO.setSaveFile(os.path.join('..',testname,filename+'.out.xml'))\n",
    "    advance()\n",
    "    CompileClass()\n",
    "    \n",
    "Compile(\"ExpressionlessSquare\", \"Square\")\n",
    "Compile(\"ExpressionlessSquare\", \"SquareGame\")\n",
    "Compile(\"ExpressionlessSquare\", \"Main\")\n",
    "\n",
    "Compile(\"Square\", \"Square\")\n",
    "Compile(\"Square\", \"SquareGame\")\n",
    "Compile(\"Square\", \"Main\")\n",
    "\n",
    "Compile(\"ArrayTest\", \"Main\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
